{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+gP5ZEWVqEVZE1nkgACcT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honzas83/t5s/blob/main/t5s/examples/t5s_csfd_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis in Czech using the t5s library\n",
        "## Install the t5s library and its dependencies"
      ],
      "metadata": {
        "id": "RtPjW3KHRl2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzc1gooiJ7RK"
      },
      "outputs": [],
      "source": [
        "%%capture pip_install\n",
        "!pip install git+https://github.com/honzas83/t5s --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and extract the Czech CSFD corpus"
      ],
      "metadata": {
        "id": "34ClMdeKRo7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://corpora.kiv.zcu.cz/sentiment/csfd.zip > csfd.zip\n",
        "!unzip -u csfd.zip"
      ],
      "metadata": {
        "id": "GOHr64kjJ8wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Czech T5-small model\n",
        "\n",
        "Equivalent of Czech T5-small model trained from Common Crawl."
      ],
      "metadata": {
        "id": "A5Z6adihRvSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1fvN7FhFA-ofiKXas73AXv3fTR6apK2rS && unzip -u t5_32k_cccs_jmzw_small.v2.zip"
      ],
      "metadata": {
        "id": "ltJ8zIXvKaQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the dataset formats\n",
        "\n",
        "The CSFD dataset consists of three files with positive, neutral and negative sentiment.\n",
        "\n",
        "This code randomly shuffles the data and generates the training, development and test data."
      ],
      "metadata": {
        "id": "m5ZsJawjSWBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "30eNIzt6Lror"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(input_files):\n",
        "    ret = []\n",
        "    for label, fn in input_files:\n",
        "        with open(fn, \"r\", encoding=\"utf-8\") as fr:\n",
        "            for line in fr:\n",
        "                text = line.strip()\n",
        "                ret.append((text, label))\n",
        "    random.shuffle(ret)\n",
        "    return ret\n",
        "\n",
        "def write_tsv(fn, data):\n",
        "    with open(fn, \"w\", encoding=\"utf-8\") as fw:\n",
        "        for text, label in data:\n",
        "            print(text, label, sep=\"\\t\", file=fw)"
      ],
      "metadata": {
        "id": "Ezm9TBN1LG2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_data([(\"pozitivní\", \"csfd/positive.txt\"), (\"negativní\", \"csfd/negative.txt\")])\n",
        "\n",
        "test_data = data[:10000]\n",
        "dev_data = data[10000:15000]\n",
        "train_data = data[15000:]\n",
        "\n",
        "write_tsv(\"csfd.train.tsv\", train_data)\n",
        "write_tsv(\"csfd.dev.tsv\", dev_data)\n",
        "write_tsv(\"csfd.test.tsv\", test_data)"
      ],
      "metadata": {
        "id": "4yipOy3zLcIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the t5s library"
      ],
      "metadata": {
        "id": "-Gk91GqySp2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from t5s import T5"
      ],
      "metadata": {
        "id": "K56k-ydhMNEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t5s configuration\n",
        "\n",
        "The configuration consists of different sections:\n",
        "\n",
        "### `tokenizer`\n",
        "\n",
        "*   `spm` - the name of the SentencePiece model\n",
        "\n",
        "### `t5_model`\n",
        "\n",
        "* `pre_trained` - the name of the pre-trained model to load for fine-tuning,\n",
        "* `save_checkpoint` - save fine-tuned checkpoints under this name,\n",
        "* `save_checkpoint_every` - integer, which specifies how often the checkpoints are saved, e.g. the value 1 means save every epoch.\n",
        "\n",
        "### `dataset`\n",
        "\n",
        "* `*_tsv` - names of TSV files used as training, development and test sets,\n",
        "* `loader` - specification how to load the training data\n",
        "  * `loader.input_size` - maximum number of input tokens in the batch\n",
        "  * `loader.output_size` - maximum number of output tokens in the batch\n",
        "  * `loader.min_batch_size` - minimum number of examples in the batch. Together with `input_size` and `output_size` specifies the maximum length of an input and an output sequence (`input_size//min_batch_size`, `output_size//min_batch_size`).\n",
        "\n",
        "### `training`\n",
        "\n",
        "* `shared_trainable` - boolean, if `True`, the parameters of shared embedding layer are trained,\n",
        "* `encoder_trainable` - boolean, if `True`, the parameters of the encoder are trained,\n",
        "* `n_epochs` - number of training epochs,\n",
        "* `initial_epoch` - number of training epochs already performed, the next epoch will be `initial_epoch+1`,\n",
        "* `steps_per_epoch` - the length of each epoch in steps, if ommited, the epoch means one pass over the training TSV,\n",
        "* `learning_rate` - initial learning rate for `epoch=1`\n",
        "* `learning_rate_schedule` - boolean, if `True`, the sqrt learning rate schedule is used. "
      ],
      "metadata": {
        "id": "7gC_bYfsSkor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"tokenizer\": {\n",
        "        \"spm\": \"t5_32k_cccs_jmzw_small.v2/T5_32k_CCcs.model\",\n",
        "    },\n",
        "    \"t5_model\": {\n",
        "        \"pre_trained\": \"t5_32k_cccs_jmzw_small.v2\",\n",
        "        \"save_checkpoint\": \"T5_csfd\",\n",
        "        \"save_checkpoint_every\": 1,\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        \"train_tsv\": \"csfd.train.tsv\",\n",
        "        \"devel_tsv\": \"csfd.dev.tsv\",\n",
        "        \"test_tsv\": \"csfd.test.tsv\",\n",
        "        \"loader\": {\n",
        "            \"input_size\": 3072,\n",
        "            \"output_size\": 256,\n",
        "            \"min_batch_size\": 4,\n",
        "        },\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"shared_trainable\": False,\n",
        "        \"encoder_trainable\": True,\n",
        "        \"n_epochs\": 5,\n",
        "        \"initial_epoch\": 0,\n",
        "        \"steps_per_epoch\": 500,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"learning_rate_schedule\": True,\n",
        "    },\n",
        "    \"predict\": {\n",
        "        \"batch_size\": 50,\n",
        "        \"max_input_length\": 768,\n",
        "        \"max_output_length\": 64,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "8OHc93owK5g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate the T5 class and fine-tune it"
      ],
      "metadata": {
        "id": "Vi0XlZkEStkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = T5(config)"
      ],
      "metadata": {
        "id": "imcI-QJZMMKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5.fine_tune()"
      ],
      "metadata": {
        "id": "Ve7yTmntMPAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict using the model\n",
        "\n",
        "The use the T5 model in code, use `predict()` method. To evaluate the model, the `predict_tsv()` could be more useful, together with evaluation using the `eval_tsv.py` script."
      ],
      "metadata": {
        "id": "OTSEpezsSwfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = []\n",
        "reference = []\n",
        "with open(\"csfd.dev.tsv\", \"r\") as fr:\n",
        "    for line in fr:\n",
        "        line = line.strip()\n",
        "        batch.append(line.split(\"\\t\")[0])\n",
        "        reference.append(line.split(\"\\t\")[1])\n",
        "        if len(batch) >= 10:\n",
        "            break\n",
        "predictions = t5.predict(batch)\n",
        "for text, ref, hyp in zip(batch, reference, predictions):\n",
        "    print(text)\n",
        "    print(\"Reference:\", ref)\n",
        "    print(\"Predicted:\", hyp)\n",
        "    print()"
      ],
      "metadata": {
        "id": "KCcQyEFZMViJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5.predict_tsv(\"csfd.dev.tsv\", \"csfd.dev.pred.tsv\")"
      ],
      "metadata": {
        "id": "lFAqBOKBQU4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation script `eval_tsv.py` takes 3 parameters - the name of metrics to compute, reference TSV and predicted TSV. The `match` metric computes sentence accuracy `SAcc` and word-level accuracy `WAcc`. The output also contains the number of correct and erroneous sentences and words. The output is in the JSON format."
      ],
      "metadata": {
        "id": "BSEvQHz1S07q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!eval_tsv.py match csfd.dev.tsv csfd.dev.pred.tsv"
      ],
      "metadata": {
        "id": "hCxvH6NxQYZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5.predict_tsv(\"csfd.test.tsv\", \"csfd.test.pred.tsv\")"
      ],
      "metadata": {
        "id": "71cfWiIGZTN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!eval_tsv.py match csfd.test.tsv csfd.test.pred.tsv"
      ],
      "metadata": {
        "id": "8kpo0PbiWUYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgS38ui1Z2Yi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}