{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honzas83/t5s/blob/main/examples/t5s_dstc11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCZYzutIFUEN"
      },
      "source": [
        "# Sentiment analysis using the t5s library\n",
        "## Install the t5s library and its dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adZxzMjPgaF0"
      },
      "source": [
        "%%capture pip_install\n",
        "!pip install git+https://github.com/honzas83/t5s --upgrade"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq65hhjaFZHJ"
      },
      "source": [
        "## Download and extract the ACL IMDB corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA61SgeTgiyK",
        "outputId": "9ca91ed7-4d55-40c2-e762-26012b133ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl https://storage.googleapis.com/gresearch/dstc11/train.tts-verbatim.2022-07-27.txt -o train.tts-verbatim.2022-07-27.txt\n",
        "!curl https://storage.googleapis.com/gresearch/dstc11/dev-dstc11.2022-07-27.txt -o dev-dstc11.2022-07-27.txt\n",
        "!curl https://storage.googleapis.com/gresearch/dstc11/test-dstc11.2022-09-21.txt -o test-dstc11.2022-09-21.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 21.2M  100 21.2M    0     0  8071k      0  0:00:02  0:00:02 --:--:-- 8069k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2892k  100 2892k    0     0  1518k      0  0:00:01  0:00:01 --:--:-- 1518k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1427k  100 1427k    0     0  1406k      0  0:00:01  0:00:01 --:--:-- 1407k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0HajwkYFfWT"
      },
      "source": [
        "## Download the T5 SentencePiece model\n",
        "\n",
        "This is the standard SentecePiece model provided by Google for their pre-trained T5 model. The `t5-base` model is downloaded by the `t5s` library (via the Huggingface Transformers library). The `gsutil` command copies the file from Google Cloud Storage bucket to the local directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_H1sepNjmLm",
        "outputId": "35b9ca48-ad4e-4e16-f35b-df1f16687067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gsutil cp -r gs://t5-data/vocabs/cc_all.32000/ .\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://t5-data/vocabs/cc_all.32000/sentencepiece.model...\n",
            "Copying gs://t5-data/vocabs/cc_all.32000/sentencepiece.vocab...\n",
            "\\ [2 files][  1.3 MiB/  1.3 MiB]                                                \n",
            "Operation completed over 2 objects/1.3 MiB.                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHMB0aHMhR3u"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import random"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFVGBWX1k3Mj"
      },
      "source": [
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "logging.basicConfig()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRoV8qmPF_hn"
      },
      "source": [
        "## Convert the dataset formats\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTcDMDy1g-Bf"
      },
      "source": [
        "def convert_to_tsv(fn_in, fn_out):\n",
        "    n = 0\n",
        "    with open(fn_out, \"w\", encoding=\"utf-8\") as fw, \\\n",
        "         open(fn_in, \"r\", encoding=\"utf-8\") as fr:\n",
        "        for line in fr:\n",
        "            line = line.strip()\n",
        "\n",
        "            if \"user:\" in line and \"turn_id: 1 \" in line:\n",
        "                try:\n",
        "                    input, output = line.strip().split(\"user:\", 1)[1].split(\"state:\", 1)\n",
        "                except ValueError:\n",
        "                    print(\"Invalid line in file\", fn_in, \":\", line)\n",
        "                    continue\n",
        "                input = input.strip()\n",
        "                output = output.strip()\n",
        "                print(input, output, sep=\"\\t\", file=fw)\n",
        "                last_state = output\n",
        "                n += 1\n",
        "    print(\"Written\", n, \"lines\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksD1rrnhApj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a87ca0-250e-44b4-e086-affa970fe40a"
      },
      "source": [
        "convert_to_tsv(\"train.tts-verbatim.2022-07-27.txt\", \"train.tsv\")\n",
        "convert_to_tsv(\"dev-dstc11.2022-07-27.txt\", \"dev.tsv\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written 8434 lines\n",
            "Written 1000 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxqF5F1uG8pW"
      },
      "source": [
        "## t5s configuration\n",
        "\n",
        "The configuration consists of different sections:\n",
        "\n",
        "### `tokenizer`\n",
        "\n",
        "*   `spm` - the name of the SentencePiece model\n",
        "\n",
        "### `t5_model`\n",
        "\n",
        "* `pre_trained` - the name of the pre-trained model to load for fine-tuning,\n",
        "* `save_checkpoint` - save fine-tuned checkpoints under this name,\n",
        "* `save_checkpoint_every` - integer, which specifies how often the checkpoints are saved, e.g. the value 1 means save every epoch.\n",
        "\n",
        "### `dataset`\n",
        "\n",
        "* `*_tsv` - names of TSV files used as training, development and test sets,\n",
        "* `loader` - specification how to load the training data\n",
        "  * `loader.input_size` - maximum number of input tokens in the batch\n",
        "  * `loader.output_size` - maximum number of output tokens in the batch\n",
        "  * `loader.min_batch_size` - minimum number of examples in the batch. Together with `input_size` and `output_size` specifies the maximum length of an input and an output sequence (`input_size//min_batch_size`, `output_size//min_batch_size`).\n",
        "\n",
        "### `training`\n",
        "\n",
        "* `shared_trainable` - boolean, if `True`, the parameters of shared embedding layer are trained,\n",
        "* `encoder_trainable` - boolean, if `True`, the parameters of the encoder are trained,\n",
        "* `n_epochs` - number of training epochs,\n",
        "* `initial_epoch` - number of training epochs already performed, the next epoch will be `initial_epoch+1`,\n",
        "* `steps_per_epoch` - the length of each epoch in steps, if ommited, the epoch means one pass over the training TSV,\n",
        "* `learning_rate` - initial learning rate for `epoch=1`\n",
        "* `learning_rate_schedule` - boolean, if `True`, the sqrt learning rate schedule is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImjrvObYi5Hd"
      },
      "source": [
        "config = {\n",
        "    \"tokenizer\": {\n",
        "        \"spm\": \"cc_all.32000/sentencepiece.model\",\n",
        "    },\n",
        "    \"t5_model\": {\n",
        "        \"pre_trained\": \"t5-base\",\n",
        "        \"save_checkpoint\": \"T5_DSTC11\",\n",
        "        \"save_checkpoint_every\": 1,\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        \"train_tsv\": \"train.tsv\",\n",
        "        \"devel_tsv\": \"dev.tsv\",\n",
        "        \"loader\": {\n",
        "            \"input_size\": 3072,\n",
        "            \"output_size\": 256,\n",
        "            \"min_batch_size\": 4,\n",
        "        },\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"shared_trainable\": False,\n",
        "        \"encoder_trainable\": True,\n",
        "        \"n_epochs\": 10,\n",
        "        \"initial_epoch\": 0,\n",
        "        \"steps_per_epoch\": 200,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"learning_rate_schedule\": True,\n",
        "    },\n",
        "    \"predict\": {\n",
        "        \"batch_size\": 50,\n",
        "        \"max_input_length\": 768,\n",
        "        \"max_output_length\": 64,\n",
        "    }\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OizcHk5JYIx"
      },
      "source": [
        "### Import the t5s library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampv7fC5krW-",
        "outputId": "5c3b3376-44bf-4eca-f89d-05e1b8024b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from t5s import T5"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh9Kjk2IJbeW"
      },
      "source": [
        "### Instantiate the T5 class and fine-tune it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mre0IQ5AktUF"
      },
      "source": [
        "t5 = T5(config)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBvYw2fmkwJn",
        "outputId": "4c75f60f-3863-4def-afdb-d8a140c153e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t5.fine_tune()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.T5:Loaded tokenizer from: cc_all.32000/sentencepiece.model\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "INFO:t5s.T5:Loading model from t5-base\n",
            "All PyTorch model weights were used when initializing T5Training.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model T5Training were not initialized from the PyTorch model and are newly initialized: ['total', 'count']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "INFO:t5s.T5:Trained model will be saved into T5_DSTC11\n",
            "INFO:t5s.T5:Training dataset: train.tsv\n",
            "INFO:t5s.T5:Development dataset: dev.tsv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.4987 - edit_accuracy: 0.9238 - loss: 0.3084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 4364 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 171s 429ms/step - sent_accuracy: 0.4987 - edit_accuracy: 0.9238 - loss: 0.3084 - val_sent_accuracy: 0.7046 - val_edit_accuracy: 0.9615 - val_loss: 0.1985 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0007071067811865475.\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.7831 - edit_accuracy: 0.9752 - loss: 0.1159"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 8522 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 77s 383ms/step - sent_accuracy: 0.7831 - edit_accuracy: 0.9752 - loss: 0.1159 - val_sent_accuracy: 0.7201 - val_edit_accuracy: 0.9623 - val_loss: 0.1837 - lr: 7.0711e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0005773502691896258.\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8360 - edit_accuracy: 0.9828 - loss: 0.0730"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 12656 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 80s 401ms/step - sent_accuracy: 0.8360 - edit_accuracy: 0.9828 - loss: 0.0730 - val_sent_accuracy: 0.7400 - val_edit_accuracy: 0.9662 - val_loss: 0.1617 - lr: 5.7735e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0005.\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8557 - edit_accuracy: 0.9856 - loss: 0.0585"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 16762 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 80s 400ms/step - sent_accuracy: 0.8557 - edit_accuracy: 0.9856 - loss: 0.0585 - val_sent_accuracy: 0.7445 - val_edit_accuracy: 0.9680 - val_loss: 0.1582 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0004472135954999579.\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8735 - edit_accuracy: 0.9878 - loss: 0.0529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 20852 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 80s 400ms/step - sent_accuracy: 0.8735 - edit_accuracy: 0.9878 - loss: 0.0529 - val_sent_accuracy: 0.7445 - val_edit_accuracy: 0.9664 - val_loss: 0.1649 - lr: 4.4721e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004082482904638631.\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8873 - edit_accuracy: 0.9893 - loss: 0.0408"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 24943 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 80s 402ms/step - sent_accuracy: 0.8873 - edit_accuracy: 0.9893 - loss: 0.0408 - val_sent_accuracy: 0.7600 - val_edit_accuracy: 0.9683 - val_loss: 0.1730 - lr: 4.0825e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0003779644730092272.\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8859 - edit_accuracy: 0.9899 - loss: 0.0373"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 29041 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 88s 440ms/step - sent_accuracy: 0.8859 - edit_accuracy: 0.9899 - loss: 0.0373 - val_sent_accuracy: 0.7356 - val_edit_accuracy: 0.9647 - val_loss: 0.1887 - lr: 3.7796e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00035355339059327376.\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8949 - edit_accuracy: 0.9904 - loss: 0.0345"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 33167 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 73s 366ms/step - sent_accuracy: 0.8949 - edit_accuracy: 0.9904 - loss: 0.0345 - val_sent_accuracy: 0.7588 - val_edit_accuracy: 0.9689 - val_loss: 0.1770 - lr: 3.5355e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0003333333333333333.\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.8964 - edit_accuracy: 0.9914 - loss: 0.0302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 37278 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 73s 364ms/step - sent_accuracy: 0.8964 - edit_accuracy: 0.9914 - loss: 0.0302 - val_sent_accuracy: 0.7400 - val_edit_accuracy: 0.9665 - val_loss: 0.1866 - lr: 3.3333e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00031622776601683794.\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - ETA: 0s - sent_accuracy: 0.9096 - edit_accuracy: 0.9924 - loss: 0.0283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.CheckpointSaver:Consumed 41386 training examples\n",
            "INFO:t5s.CheckpointSaver:Saving checkpoint to T5_DSTC11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "200/200 [==============================] - 76s 381ms/step - sent_accuracy: 0.9096 - edit_accuracy: 0.9924 - loss: 0.0283 - val_sent_accuracy: 0.7467 - val_edit_accuracy: 0.9667 - val_loss: 0.1913 - lr: 3.1623e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI93aR7AyMG-"
      },
      "source": [
        "## Predict using the model\n",
        "\n",
        "To use the T5 model in code, use the `predict()` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head dev.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFjORS-m-mbF",
        "outputId": "d3d36b85-dcb1-488d-b7fc-fc9ea9aa0e1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i need to book a hotel in the east that has 4 stars.\thotel-area=east; hotel-stars=4\n",
            "howdy, i need a train heading into floyd.\ttrain-destination=floyd\n",
            "what can you tell me about the eleven madison park?\trestaurant-name=eleven madison park\n",
            "i am looking for a specific hotel, its name is disney's contemporary resort\thotel-name=disney's contemporary resort\n",
            "hi i'm looking for lodging in cambridge that includes free wifi and is upscale and expensive\thotel-pricerange=expensive; hotel-internet=yes\n",
            "can you recommend some fun entertainment in the centre?\tattraction-area=centre\n",
            "i looking for information about a hotel in the moderate price range that includes free wifi.\thotel-pricerange=moderate; hotel-internet=yes\n",
            "hello, i am trying to find a place to stay that has free wifi and 3 stars. do you have anything like that?\thotel-stars=3; hotel-internet=yes\n",
            "i'm looking for a italian restaurant centre.\trestaurant-food=italian; restaurant-area=centre\n",
            "i'm looking for a train that departs ripley after 1:42 am.\ttrain-leaveat=1:42 am; train-departure=ripley\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qjVbRHlyStn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7af3edb-595c-47d6-d866-a186c95a0e24"
      },
      "source": [
        "batch = []\n",
        "reference = []\n",
        "with open(\"dev.tsv\", \"r\") as fr:\n",
        "    for line in fr:\n",
        "        line = line.strip()\n",
        "        batch.append(line.split(\"\\t\")[0])\n",
        "        reference.append(line.split(\"\\t\")[1])\n",
        "        if len(batch) >= 10:\n",
        "            break\n",
        "predictions = t5.predict(batch)\n",
        "for text, ref, hyp in zip(batch, reference, predictions):\n",
        "    print(text)\n",
        "    print(\"Reference:\", ref)\n",
        "    print(\"Predicted:\", hyp)\n",
        "    print()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:t5s.T5:Loaded tokenizer from: cc_all.32000/sentencepiece.model\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:399: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i need to book a hotel in the east that has 4 stars.\n",
            "Reference: hotel-area=east; hotel-stars=4\n",
            "Predicted: hotel-area=east; hotel-stars=4\n",
            "\n",
            "howdy, i need a train heading into floyd.\n",
            "Reference: train-destination=floyd\n",
            "Predicted: train-destination=fliyd\n",
            "\n",
            "what can you tell me about the eleven madison park?\n",
            "Reference: restaurant-name=eleven madison park\n",
            "Predicted: attraction-name=11 madison park\n",
            "\n",
            "i am looking for a specific hotel, its name is disney's contemporary resort\n",
            "Reference: hotel-name=disney's contemporary resort\n",
            "Predicted: hotel-name=disneys contemporary resort\n",
            "\n",
            "hi i'm looking for lodging in cambridge that includes free wifi and is upscale and expensive\n",
            "Reference: hotel-pricerange=expensive; hotel-internet=yes\n",
            "Predicted: hotel-pricerange=expensive; hotel-internet=yes\n",
            "\n",
            "can you recommend some fun entertainment in the centre?\n",
            "Reference: attraction-area=centre\n",
            "Predicted: attraction-area=centre\n",
            "\n",
            "i looking for information about a hotel in the moderate price range that includes free wifi.\n",
            "Reference: hotel-pricerange=moderate; hotel-internet=yes\n",
            "Predicted: hotel-pricerange=moderate; hotel-internet=yes\n",
            "\n",
            "hello, i am trying to find a place to stay that has free wifi and 3 stars. do you have anything like that?\n",
            "Reference: hotel-stars=3; hotel-internet=yes\n",
            "Predicted: hotel-stars=3; hotel-internet=yes\n",
            "\n",
            "i'm looking for a italian restaurant centre.\n",
            "Reference: restaurant-food=italian; restaurant-area=centre\n",
            "Predicted: restaurant-food=italian; restaurant-area=centre\n",
            "\n",
            "i'm looking for a train that departs ripley after 1:42 am.\n",
            "Reference: train-leaveat=1:42 am; train-departure=ripley\n",
            "Predicted: train-leaveat=1:42 am; train-departure=ripley\n",
            "\n"
          ]
        }
      ]
    }
  ]
}